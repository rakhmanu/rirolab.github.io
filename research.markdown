---
layout: page
title: Research Areas
permalink: /research/
---


<td markdown="span">
    <a href="/assets/research/research_areas.png" data-lightbox="Research Areas" >
      <img style="width: 1000px" src="/assets/research/research_areas.png">
      </a>
</td>


<table cellpadding="20px">
<colgroup>
<col width="30%" />
<col width="70%" />
</colgroup>
<thead>
<tr class="header">
<th><h3>Topic</h3></th>
<th><h3>Description</h3></th>
</tr>
</thead>
<tbody>
<tr>
<td markdown="span">
    <a href="/assets/research/2019_CoRL_CBN_IRL2.png" data-lightbox="corl19_cbnirl" >
      <img style="width: 350px" src="/assets/research/2019_CoRL_CBN_IRL.png">
    </a>
</td>
<td markdown="span">
**Inverse Manipulation Skill Learning**
<!--![](//www.youtube.com/watch?v=HgaqH4PWcTI?width=100height=50)-->
<br>
Learning for manipulation is to obtain manipulation skills from a wide range of knowledge sources. We introduce methodologies for learning manipulation constraints and motion parameters from demonstrations.
<br>
<br>
**Selected paper**: Daehyung Park, Michael Noseworthy, Rohan Paul, Subhro Roy, and Nicholas Roy. "Inferring Task Goals and Constraints using Bayesian Nonparametric Inverse Reinforcement Learning", Conference on Robot Learning (CoRL2019) 
<a href="https://drive.google.com/open?id=1bswpgVJDXp_9vh55_Gz1cAbylhhjQqhS" target="_blank">[PDF]</a><a href="https://youtu.be/HgaqH4PWcTI" target="_blank">[Video]</a>
</td>
</tr>
<tr>
<td markdown="span">
    <a href="/assets/research/2021_RAL_LTL_BT.png" data-lightbox="ral20_ltl_bt" >
      <img style="width: 350px" src="/assets/research/2021_RAL_LTL_BT.png">
      </a>
</td>
<td markdown="span">
**Dynamically Reconfigurable Task-and-Motion Planning**
<br> We present a robust task-and-motion planning(TAMP) framework under human operator’s cooperative oradversarial interventions.
</td>
</tr>

<tr>
<td markdown="span">
    <a href="/assets/research/2020_IJRR.png" data-lightbox="ijrr20" >
      <img style="width: 350px" src="/assets/research/2020_IJRR.png">
      </a>
</td>
<td markdown="span">
 **Natural Language Understanding for Manipulation**
<br>Natural language is a convenient means to deliver a user’s high-level instruction. We introduce a language-guided manipulation framework that learns common-sense knowledge from natural language instructions and corresponding motion demonstrations.
<br>
<br>
**Selected paper**: Daehyung Park#, Jacob Arkin#, Subhro Roy, Matthew R. Walter, Nicholas Roy, Thomas M. Howard, and Rohan Paul. "Multi-Modal Estimation and Communication of Latent Semantic Knowledge for Robust Execution of Robot Instructions", The International Journal of Robotics Research (IJRR), 2020. (#- authors contributed equally) 
<a href="https://journals.sagepub.com/eprint/PSW4Z5AXF4AYTSXRN7AI/full" target="_blank">[PDF]</a><a href="https://www.youtube.com/watch?v=BfCeYsTvaOw&amp" target="_blank">[Video]</a>
</td>
</tr>

<tr>
<td markdown="span">
    <a href="/assets/research/2018_CORL.png" data-lightbox="CoRL2018" >
      <img style="width: 350px" src="/assets/research/2018_CORL.png">
      </a>
</td>
<td markdown="span">
**Machine Common Sense Learning for Robots**
<br>Interpreting underspecified instructions re-quires environmental context and background knowledge about how to accomplish complex tasks. We investigate how to incorporate human-like commonsense knowledge for natural language understanding and task executions. You can find related papers as follows,
<br>
<br>
**Selected paper**: Daniel Nyga, Subhro Roy, Rohan Paul, Daehyung Park, Mihai Pomarlan, Michael Beetz, and Nicholas Roy. "Grounding Robot Plans from Natural Language Instructions with Incomplete World Knowledge", Conf. on Robot Learning (CoRL2018)
<a href="http://proceedings.mlr.press/v87/nyga18a/nyga18a.pdf" target="_blank">[PDF]</a><a href="https://youtu.be/uWv-l7XMoB8" target="_blank">[Video]</a>
</td>
</tr>

</tbody>
</table>


